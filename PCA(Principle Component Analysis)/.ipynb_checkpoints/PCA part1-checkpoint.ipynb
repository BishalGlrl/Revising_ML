{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e86e693-6d8f-42fd-82d6-c3f0b4bc8b73",
   "metadata": {},
   "source": [
    "### PCA stands for principle component analysis.Human eyes cannot sees more than 3 dimensional data.So PCA shows the multidimensional data into a form that we can visualize(3D or 2D).Just like a camaraman captures a 2D picture of the 3D fields from each angle without missing any essence and moment.PCA too shows all the essential detail of the dataset in a 2D or 3D form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62439048-1a83-472d-a3be-7baf9c20dc22",
   "metadata": {},
   "source": [
    "<h2 style = 'color:purple;'>Feature Selection:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c244963-046b-424a-bbe8-1af1264848c4",
   "metadata": {},
   "source": [
    "## lets suppose we have 100 features and we dont have domain knowledge of every feature,now as datascientist if we only want to keep the important features and drop other non important,then we plot a graph as follow\n",
    "<img src = 'feature.png'/>\n",
    "\n",
    "## Here we can see that 'd' is city is less than 'd' in no of rooms,so room column is more important.HEnce we can drop city column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2822d-9ec8-4664-a7f8-9f63dfc5be8d",
   "metadata": {},
   "source": [
    "### The main problem with feature selection is that when both d are equal to each other,then it creates conflict in selecting the appropriate column.For eg when there are two columns \"No. of washroom\" and \"No of romms\" in house price prediction,then this creates a confusion as these two may have a linear relation where both d are equal to each other as below\n",
    "<img src='2feature.png'/>\n",
    "\n",
    "### Here both column have same d making hard to select a feature.These limitation can be overcomed by feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0cadd2-9df9-4f9c-946b-9314c0176efe",
   "metadata": {},
   "source": [
    "<h2 style = 'color : purple;'>Feature Extraction :</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12302ba0-0ea1-4ee7-af3b-261250338c1d",
   "metadata": {},
   "source": [
    "### Now when we apply feature extraction to the data above,the feature extraction can make a new feature named as \"Size\" by combining both the washrooms and Rooms with its corresponding price.This is whaat exactly PCA does.PCA forgets the old features and generate the new feature of its own making us easier to analyse our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29574a3-473b-44f2-8a58-8feaaa658319",
   "metadata": {},
   "source": [
    "<h2 style = 'color:purple'>PCA:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579711b-8584-44e9-abca-aa71dd3d7bf5",
   "metadata": {},
   "source": [
    "### In above same problem,PCA rotate the axis in a small angle and then again analyse the d's of both the features.From below we can see that d' of 'washroom' is more so it is more important.Hence we have to keep this column.The new feature thus formed is called PC1 and PC2\n",
    "<img src='PCA.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db8956-c161-4b14-9d9c-eb89f88c5ec1",
   "metadata": {},
   "source": [
    "<h2 style ='color:purple'>Variance gives us the understanding of how well the data is spread out from mean.High variance means The data points are far from the mean and from each other.Low variance means data are clustured together around the mean</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005eca8b-7500-405e-bf67-90b256d7ebf6",
   "metadata": {},
   "source": [
    "<img src='variance.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d5c4d-6565-4c57-a00d-fe8ad6c9e604",
   "metadata": {},
   "source": [
    "### In above figure,points in below subplot have larger distance from mean so variance is high and just vice versa for the figure above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f97099-033f-4cf6-8d40-7f562f8d9fb2",
   "metadata": {},
   "source": [
    "### Variance is important in PCA as by focusing on high variance data that captures important information,PCA can capture important pattern.Lets take example of camaraman,High variance data means data haru dherei spread vako.So if camaraman captures the picture from when data are spread welly,then all the data can be captured well(football player haru sabbai aauxan).But camaraman captures picture from low variance then low information would be captured.I.e 2 3 jana football player matra aauxan camara ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c530dc6-5d91-4751-9f49-fb4c2a9d4911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
